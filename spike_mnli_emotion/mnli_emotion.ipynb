{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class MNLILabel(Enum):\n",
    "    ENTAILMENT = 0\n",
    "    NEUTRAL = 1\n",
    "    CONTRADICTION = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conceptually cream skimming has two basic dimensions - product and geography.\n",
      "Product and geography are what make cream skimming work.\n",
      "MNLILabel.NEUTRAL\n"
     ]
    }
   ],
   "source": [
    "for item in data:\n",
    "    print(item[\"premise\"])\n",
    "    print(item[\"hypothesis\"])\n",
    "    print(MNLILabel(item[\"label\"]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "from anthropic import Anthropic\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    max_tokens=1024,\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Here is a premise and hypothesis pair. Tell me if the relationship between them is entailment, neutral, or contradiction:\\n\\n\" + \n",
    "                  f\"Premise: {data[0]['premise']}\\n\" +\n",
    "                  f\"Hypothesis: {data[0]['hypothesis']}\"\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me analyze this carefully:\n",
      "\n",
      "The relationship between the premise and hypothesis is NEUTRAL.\n",
      "\n",
      "Here's why:\n",
      "- The premise states that cream skimming has two basic dimensions: product and geography\n",
      "- The hypothesis makes a stronger claim, stating that these two elements \"make cream skimming work\"\n",
      "- While the premise identifies these as dimensions of cream skimming, it doesn't make any claims about whether these dimensions are what make it successful or functional\n",
      "- The hypothesis goes beyond the information given in the premise by making a claim about causation/functionality\n",
      "\n",
      "Since we can't determine from the premise alone whether product and geography are what make cream skimming work (as opposed to just being descriptive dimensions), we cannot say the premise entails the hypothesis, nor does it contradict it. Therefore, the relationship is neutral.\n"
     ]
    }
   ],
   "source": [
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract emotion info from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class EmotionInfo(BaseModel):\n",
    "    arousal: float = Field(ge=0, le=1, description=\"Level of energy/activation in the emotion, from calm (0) to excited (1)\")\n",
    "    valence: float = Field(ge=0, le=1, description=\"Pleasantness of the emotion, from negative (0) to positive (1)\")\n",
    "    intensity: float = Field(ge=0, le=1, description=\"Overall strength of the emotional response, from weak (0) to strong (1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_info_schema = json.dumps(EmotionInfo.model_json_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "from anthropic import Anthropic\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def get_emotion_info(\n",
    "        input_text: str, \n",
    "        parse_error: str | None = None, \n",
    "        previous_output: str | None = None,\n",
    "        try_count: int = 0,\n",
    "        max_retries: int = 3\n",
    "    ):\n",
    "    client = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "    \n",
    "    prompt = f\"\"\"Analyze the emotional content of this text and output a JSON object with the following schema:\n",
    "    {emotion_info_schema}\n",
    "    \n",
    "    Only output valid JSON, nothing else.\n",
    "    \n",
    "    Text to analyze: {input_text}\"\"\"\n",
    "\n",
    "    if parse_error:\n",
    "        prompt += f\"You already outputted the following JSON, but it was invalid:\\n{previous_output}\\nValidation errors: {parse_error}\\nPlease fix the errors and output a valid JSON.\"\n",
    "\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        max_tokens=1024,\n",
    "        messages=[{\n",
    "            \"role\": \"user\", \n",
    "            \"content\": prompt\n",
    "        }]\n",
    "    )\n",
    "    try:\n",
    "        response_json = json.loads(message.content[0].text)\n",
    "        return response_json\n",
    "    except json.JSONDecodeError as e:\n",
    "        return get_emotion_info(input_text, str(e), message.content[0].text, try_count + 1, max_retries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "augmented_data = []\n",
    "for item in data:\n",
    "    emotion_info_premise = get_emotion_info(item[\"premise\"])\n",
    "    emotion_info_hypothesis = get_emotion_info(item[\"hypothesis\"])\n",
    "\n",
    "    augmented_data.append({\n",
    "        \"premise\": item[\"premise\"],\n",
    "        \"hypothesis\": item[\"hypothesis\"],\n",
    "        \"emotion_info_premise\": emotion_info_premise,\n",
    "        \"emotion_info_hypothesis\": emotion_info_hypothesis,\n",
    "        \"label\": item[\"label\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(augmented_data, open(\"augmented_data.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now at scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dariogod/.pyenv/versions/3.11.9/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"nyu-mll/glue\", \"mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"premise\": \"Conceptually cream skimming has two basic dimensions - product and geography.\",\n",
      "    \"hypothesis\": \"Product and geography are what make cream skimming work. \",\n",
      "    \"label\": 1,\n",
      "    \"idx\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(ds[\"train\"][0], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_emotion_info_async(\n",
    "        input_text: str, \n",
    "        parse_error: str | None = None, \n",
    "        previous_output: str | None = None,\n",
    "        try_count: int = 0,\n",
    "        max_retries: int = 3\n",
    "    ):\n",
    "    client = anthropic.AsyncAnthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "    \n",
    "    prompt = f\"\"\"Analyze the emotional content of this text and output a JSON object with the following schema:\n",
    "    {emotion_info_schema}\n",
    "    \n",
    "    Only output valid JSON, nothing else.\n",
    "    \n",
    "    Text to analyze: {input_text}\"\"\"\n",
    "\n",
    "    if parse_error:\n",
    "        prompt += f\"You already outputted the following JSON, but it was invalid:\\n{previous_output}\\nValidation errors: {parse_error}\\nPlease fix the errors and output a valid JSON.\"\n",
    "\n",
    "    message = await client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        max_tokens=1024,\n",
    "        messages=[{\n",
    "            \"role\": \"user\", \n",
    "            \"content\": prompt\n",
    "        }]\n",
    "    )\n",
    "    try:\n",
    "        response_json = json.loads(message.content[0].text)\n",
    "        return response_json\n",
    "    except json.JSONDecodeError as e:\n",
    "        if try_count >= max_retries:\n",
    "            raise e\n",
    "        return await get_emotion_info_async(input_text, str(e), message.content[0].text, try_count + 1, max_retries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"augmented_data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def process_batch(batch_start, batch_size, ds):\n",
    "    sem = asyncio.Semaphore(5)  # Limit to 5 concurrent tasks\n",
    "    augmented_batch = []\n",
    "    \n",
    "    async def process_item(item):\n",
    "        async with sem:\n",
    "            emotion_info_premise, emotion_info_hypothesis = await asyncio.gather(\n",
    "                get_emotion_info_async(item[\"premise\"]),\n",
    "                get_emotion_info_async(item[\"hypothesis\"])\n",
    "            )\n",
    "            return {\n",
    "                \"idx\": item[\"idx\"],\n",
    "                \"premise\": {\n",
    "                    \"text\": item[\"premise\"],\n",
    "                    \"emotion_info\": emotion_info_premise\n",
    "                },\n",
    "                \"hypothesis\": {\n",
    "                    \"text\": item[\"hypothesis\"],\n",
    "                    \"emotion_info\": emotion_info_hypothesis\n",
    "                },\n",
    "                \"label\": item[\"label\"]\n",
    "            }\n",
    "\n",
    "    # Create tasks for all items in the batch\n",
    "    tasks = [\n",
    "        process_item(ds[\"train\"][i]) \n",
    "        for i in range(batch_start, batch_start + batch_size)\n",
    "    ]\n",
    "    \n",
    "    # Wait for all tasks to complete and collect results\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    augmented_batch.extend(results)\n",
    "    \n",
    "    return augmented_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "TOTAL_SIZE = 1000\n",
    "BATCH_START = 20\n",
    "\n",
    "for batch_start in range(BATCH_START, TOTAL_SIZE, BATCH_SIZE):\n",
    "    augmented_batch = await process_batch(batch_start, BATCH_SIZE, ds)\n",
    "    with open(f\"augmented_data/batch_{batch_start}-{batch_start+BATCH_SIZE}.json\", \"w\") as f:\n",
    "        json.dump(augmented_batch, f)\n",
    "    # Wait 60 seconds before processing next batch\n",
    "    await asyncio.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
