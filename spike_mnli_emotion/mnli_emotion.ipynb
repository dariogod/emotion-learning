{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class MNLILabel(Enum):\n",
    "    ENTAILMENT = 0\n",
    "    NEUTRAL = 1 \n",
    "    CONTRADICTION = 2\n",
    "\n",
    "int_to_label = {key: value for key, value in enumerate(MNLILabel)}\n",
    "label_to_int = {value: key for key, value in int_to_label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conceptually cream skimming has two basic dimensions - product and geography.\n",
      "Product and geography are what make cream skimming work.\n",
      "MNLILabel.NEUTRAL\n"
     ]
    }
   ],
   "source": [
    "for item in data:\n",
    "    print(item[\"premise\"])\n",
    "    print(item[\"hypothesis\"])\n",
    "    print(MNLILabel(item[\"label\"]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlock(citations=None, text='The relationship between this premise and hypothesis is NEUTRAL.\\n\\nHere\\'s why:\\n- The premise states that cream skimming has two basic dimensions: product and geography\\n- The hypothesis makes a stronger claim that these two dimensions are what \"make cream skimming work\"\\n- While the premise identifies these dimensions as components, it doesn\\'t make any claims about their role in making cream skimming successful or functional\\n- The hypothesis goes beyond the information provided in the premise by making an assertion about effectiveness/functionality\\n\\nThe hypothesis might be true, but we cannot determine this solely from the information given in the premise. Therefore, the relationship is neutral.', type='text')\n"
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "from anthropic import Anthropic\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    max_tokens=1024,\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Here is a premise and hypothesis pair. Tell me if the relationship between them is entailment, neutral, or contradiction:\\n\\n\" + \n",
    "                  f\"Premise: {data[0]['premise']}\\n\" +\n",
    "                  f\"Hypothesis: {data[0]['hypothesis']}\"\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(message.content[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The relationship between this premise and hypothesis is NEUTRAL.\n",
      "\n",
      "Here's why:\n",
      "- The premise states that cream skimming has two basic dimensions: product and geography\n",
      "- The hypothesis makes a stronger claim that these two dimensions are what \"make cream skimming work\"\n",
      "- While the premise identifies these dimensions as components, it doesn't make any claims about their role in making cream skimming successful or functional\n",
      "- The hypothesis goes beyond the information provided in the premise by making an assertion about effectiveness/functionality\n",
      "\n",
      "The hypothesis might be true, but we cannot determine this solely from the information given in the premise. Therefore, the relationship is neutral.\n"
     ]
    }
   ],
   "source": [
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class EmotionInfo(BaseModel):\n",
    "    arousal: float = Field(ge=0, le=1, description=\"Level of energy/activation in the emotion, from calm (0) to excited (1)\")\n",
    "    valence: float = Field(ge=0, le=1, description=\"Pleasantness of the emotion, from negative (0) to positive (1)\")\n",
    "    intensity: float = Field(ge=0, le=1, description=\"Overall strength of the emotional response, from weak (0) to strong (1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_info_schema = json.dumps(EmotionInfo.model_json_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "from anthropic import Anthropic\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def get_emotion_info(\n",
    "        input_text: str, \n",
    "        parse_error: str | None = None, \n",
    "        previous_output: str | None = None,\n",
    "        try_count: int = 0,\n",
    "        max_retries: int = 3\n",
    "    ):\n",
    "    client = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "    \n",
    "    prompt = f\"\"\"Analyze the emotional content of this text and output a JSON object with the following schema:\n",
    "    {emotion_info_schema}\n",
    "    \n",
    "    Only output valid JSON, nothing else.\n",
    "    \n",
    "    Text to analyze: {input_text}\"\"\"\n",
    "\n",
    "    if parse_error:\n",
    "        prompt += f\"You already outputted the following JSON, but it was invalid:\\n{previous_output}\\nValidation errors: {parse_error}\\nPlease fix the errors and output a valid JSON.\"\n",
    "\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        max_tokens=1024,\n",
    "        messages=[{\n",
    "            \"role\": \"user\", \n",
    "            \"content\": prompt\n",
    "        }]\n",
    "    )\n",
    "    try:\n",
    "        response_json = json.loads(message.content[0].text)\n",
    "        return response_json\n",
    "    except json.JSONDecodeError as e:\n",
    "        return get_emotion_info(input_text, str(e), message.content[0].text, try_count + 1, max_retries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "augmented_data = []\n",
    "for item in data:\n",
    "    emotion_info_premise = get_emotion_info(item[\"premise\"])\n",
    "    emotion_info_hypothesis = get_emotion_info(item[\"hypothesis\"])\n",
    "\n",
    "    augmented_data.append({\n",
    "        \"premise\": item[\"premise\"],\n",
    "        \"hypothesis\": item[\"hypothesis\"],\n",
    "        \"emotion_info_premise\": emotion_info_premise,\n",
    "        \"emotion_info_hypothesis\": emotion_info_hypothesis,\n",
    "        \"label\": item[\"label\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(augmented_data, open(\"augmented_data.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
