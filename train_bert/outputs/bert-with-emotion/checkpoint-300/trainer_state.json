{
  "best_global_step": 200,
  "best_metric": 0.35042956471443176,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 100,
  "global_step": 300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1,
      "grad_norm": 3.640068292617798,
      "learning_rate": 4.85e-05,
      "loss": 0.4341,
      "step": 10
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.8848645687103271,
      "learning_rate": 4.683333333333334e-05,
      "loss": 0.4151,
      "step": 20
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.8252110481262207,
      "learning_rate": 4.516666666666667e-05,
      "loss": 0.3777,
      "step": 30
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.7942323684692383,
      "learning_rate": 4.35e-05,
      "loss": 0.417,
      "step": 40
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.5775983333587646,
      "learning_rate": 4.183333333333334e-05,
      "loss": 0.4446,
      "step": 50
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.07707142829895,
      "learning_rate": 4.016666666666667e-05,
      "loss": 0.4126,
      "step": 60
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.624298095703125,
      "learning_rate": 3.85e-05,
      "loss": 0.3538,
      "step": 70
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9000037908554077,
      "learning_rate": 3.683333333333334e-05,
      "loss": 0.3524,
      "step": 80
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.0091745853424072,
      "learning_rate": 3.516666666666667e-05,
      "loss": 0.4066,
      "step": 90
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.074491024017334,
      "learning_rate": 3.35e-05,
      "loss": 0.3532,
      "step": 100
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.525,
      "eval_loss": 0.3652166724205017,
      "eval_runtime": 3.4107,
      "eval_samples_per_second": 58.638,
      "eval_steps_per_second": 7.33,
      "step": 100
    },
    {
      "epoch": 1.1,
      "grad_norm": 3.141451358795166,
      "learning_rate": 3.183333333333334e-05,
      "loss": 0.3013,
      "step": 110
    },
    {
      "epoch": 1.2,
      "grad_norm": 3.994209051132202,
      "learning_rate": 3.016666666666667e-05,
      "loss": 0.2806,
      "step": 120
    },
    {
      "epoch": 1.3,
      "grad_norm": 4.617790699005127,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 0.2762,
      "step": 130
    },
    {
      "epoch": 1.4,
      "grad_norm": 4.413424015045166,
      "learning_rate": 2.6833333333333333e-05,
      "loss": 0.3035,
      "step": 140
    },
    {
      "epoch": 1.5,
      "grad_norm": 5.133329391479492,
      "learning_rate": 2.5166666666666667e-05,
      "loss": 0.3389,
      "step": 150
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.49922776222229,
      "learning_rate": 2.35e-05,
      "loss": 0.2962,
      "step": 160
    },
    {
      "epoch": 1.7,
      "grad_norm": 6.217052936553955,
      "learning_rate": 2.1833333333333333e-05,
      "loss": 0.2591,
      "step": 170
    },
    {
      "epoch": 1.8,
      "grad_norm": 4.854674816131592,
      "learning_rate": 2.0166666666666668e-05,
      "loss": 0.279,
      "step": 180
    },
    {
      "epoch": 1.9,
      "grad_norm": 2.055081844329834,
      "learning_rate": 1.85e-05,
      "loss": 0.2833,
      "step": 190
    },
    {
      "epoch": 2.0,
      "grad_norm": 10.307571411132812,
      "learning_rate": 1.6833333333333334e-05,
      "loss": 0.3044,
      "step": 200
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.59,
      "eval_loss": 0.35042956471443176,
      "eval_runtime": 3.3733,
      "eval_samples_per_second": 59.29,
      "eval_steps_per_second": 7.411,
      "step": 200
    },
    {
      "epoch": 2.1,
      "grad_norm": 3.7676713466644287,
      "learning_rate": 1.5166666666666668e-05,
      "loss": 0.1726,
      "step": 210
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.7880489826202393,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 0.1598,
      "step": 220
    },
    {
      "epoch": 2.3,
      "grad_norm": 1.0302181243896484,
      "learning_rate": 1.1833333333333334e-05,
      "loss": 0.1767,
      "step": 230
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.9167253971099854,
      "learning_rate": 1.0166666666666667e-05,
      "loss": 0.1097,
      "step": 240
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.939647912979126,
      "learning_rate": 8.500000000000002e-06,
      "loss": 0.158,
      "step": 250
    },
    {
      "epoch": 2.6,
      "grad_norm": 7.919066429138184,
      "learning_rate": 6.833333333333333e-06,
      "loss": 0.1405,
      "step": 260
    },
    {
      "epoch": 2.7,
      "grad_norm": 1.5456712245941162,
      "learning_rate": 5.166666666666667e-06,
      "loss": 0.1385,
      "step": 270
    },
    {
      "epoch": 2.8,
      "grad_norm": 4.587003231048584,
      "learning_rate": 3.5000000000000004e-06,
      "loss": 0.0939,
      "step": 280
    },
    {
      "epoch": 2.9,
      "grad_norm": 3.695241928100586,
      "learning_rate": 1.8333333333333335e-06,
      "loss": 0.1612,
      "step": 290
    },
    {
      "epoch": 3.0,
      "grad_norm": 5.072910785675049,
      "learning_rate": 1.6666666666666668e-07,
      "loss": 0.1471,
      "step": 300
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.585,
      "eval_loss": 0.4196144938468933,
      "eval_runtime": 3.4533,
      "eval_samples_per_second": 57.916,
      "eval_steps_per_second": 7.24,
      "step": 300
    }
  ],
  "logging_steps": 10,
  "max_steps": 300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
